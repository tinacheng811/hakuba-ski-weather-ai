{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172d0289-fca8-4e12-a589-c328f27fa050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import pickle # ç”¨ä¾†è¼‰å…¥ä½ çš„ scaler\n",
    "\n",
    "# 1. ç¶²é æ¨™é¡Œèˆ‡é¸å–®\n",
    "st.set_page_config(page_title=\"ç™½é¦¬æ‘æ»‘é›ªå¤©æ°£AIåŠ©ç†\", page_icon=\"â„ï¸\")\n",
    "st.title(\"â„ï¸ ç™½é¦¬æ‘æ»‘é›ªå¤©æ°£AIåŠ©ç†\")\n",
    "st.write(\"é€éLSTMæ·±åº¦å­¸ç¿’æ¨¡å‹é æ¸¬æœ€ä½³æ»‘é›ªæ™‚æ©Ÿ\")\n",
    "\n",
    "# 2. å´é‚Šæ¬„ï¼šä½¿ç”¨è€…è¼¸å…¥\n",
    "st.sidebar.header(\"è«‹é¸æ“‡æ‚¨çš„æ—…éŠæœŸé–“:\")\n",
    "start_date = st.sidebar.date_input(\"é–‹å§‹æ—¥æœŸ:\")\n",
    "end_date = st.sidebar.date_input(\"çµæŸæ—¥æœŸ:\")\n",
    "\n",
    "# 3. è¼‰å…¥æ¨¡å‹èˆ‡å·¥å…· (é€™éƒ¨åˆ†å»ºè­°å…ˆåœ¨ Colab å„²å­˜å¥½)\n",
    "# @st.cache_resource ç¢ºä¿æ¨¡å‹åªæœƒè¼‰å…¥ä¸€æ¬¡ï¼Œç¯€çœæ‰‹æ©Ÿé–‹å•Ÿæ™‚é–“\n",
    "@st.cache_resource\n",
    "def load_ai_assets():\n",
    "    model = load_model('my_lstm_model.h5')\n",
    "    with open('scaler.pkl', 'rb') as f:\n",
    "        scaler = pickle.load(f)\n",
    "    return model, scaler\n",
    "\n",
    "# 4. æ ¸å¿ƒé‚è¼¯ (å°‡ä½ ä¹‹å‰çš„ get_ski_recommendation æ”¾é€²ä¾†)\n",
    "def get_ski_recommendation(start_date_str, end_date_str, model, scaler, df, window_size=7):\n",
    "    # 1. æ™‚é–“æ ¼å¼è½‰æ›\n",
    "    start_date = pd.to_datetime(start_date_str)\n",
    "    end_date = pd.to_datetime(end_date_str)\n",
    "    last_date = df['Date'].max()\n",
    "    \n",
    "    # 2. å®šç¾©ç‰¹å¾µæ¬„ä½ (å¿…é ˆæ˜¯è¨“ç·´æ™‚çš„ 9 å€‹)\n",
    "    features_cols = ['tavg', 'tmax', 'tmin', 'prcp', 'snowf', 'snowdmax', 'sunhour', 'month_sin', 'month_cos']\n",
    "    \n",
    "    # 3. æº–å‚™å„²å­˜çµæœçš„æ¸…å–®\n",
    "    predictions_list = []\n",
    "\n",
    "    # 4. åˆ¤æ–·å€é–“è½åœ¨ã€Œæ­·å²ã€é‚„æ˜¯ã€Œæœªä¾†ã€\n",
    "    # å¦‚æœå€é–“å®Œå…¨åœ¨æ­·å²å…§ï¼Œç›´æ¥å¾ df æŠ“\n",
    "    if end_date <= last_date:\n",
    "        relevant_df = df[(df['Date'] >= start_date) & (df['Date'] <= end_date)]\n",
    "        for _, row in relevant_df.iterrows():\n",
    "            predictions_list.append({\n",
    "                'date': row['Date'],\n",
    "                'tavg': row['tavg'], 'tmax': row['tmax'], 'tmin': row['tmin'],\n",
    "                'snowf': row['snowf'], 'snowdmax': row['snowf'] # æ­·å²è³‡æ–™å¯èƒ½å«ä¸åŒå\n",
    "            })\n",
    "    else:\n",
    "        # å¦‚æœåŒ…å«æœªä¾†ï¼ŒåŸ·è¡Œ LSTM éè¿´é æ¸¬\n",
    "        days_to_predict = (end_date - last_date).days\n",
    "        \n",
    "        # æº–å‚™æœ€å¾Œ window_size å¤©çš„è³‡æ–™ä½œç‚ºå•Ÿå‹•ç¨®å­\n",
    "        last_data_raw = df[features_cols].tail(window_size).fillna(0).values\n",
    "        current_batch = scaler.transform(last_data_raw).reshape(1, window_size, 9)\n",
    "\n",
    "        for i in range(days_to_predict):\n",
    "            # æ¨¡å‹è¼¸å‡º 5 å€‹å€¼: [tavg, tmax, tmin, snowf, snowdmax]\n",
    "            pred = model.predict(current_batch, verbose=0)[0]\n",
    "            curr_date = last_date + pd.Timedelta(days=i+1)\n",
    "\n",
    "            # å¦‚æœé€™å¤©åœ¨éŠå®¢è¦æ±‚çš„å€é–“å…§ï¼Œå‰‡é‚„åŸä¸¦è¨˜éŒ„\n",
    "            if start_date <= curr_date <= end_date:\n",
    "                dummy = np.zeros((1, 9))\n",
    "                dummy[0, 0:3] = pred[0:3] # tavg, tmax, tmin\n",
    "                dummy[0, 4:6] = pred[3:5] # snowf, snowdmax\n",
    "                res = scaler.inverse_transform(dummy)[0]\n",
    "                \n",
    "                predictions_list.append({\n",
    "                    'date': curr_date,\n",
    "                    'tavg': res[0], 'tmax': res[1], 'tmin': res[2],\n",
    "                    'snowf': res[4], 'snowdmax': res[5]\n",
    "                })\n",
    "\n",
    "            # æ›´æ–°ä¸‹ä¸€å¤©çš„è¼¸å…¥ (ç¶­æŒ 9 ç‰¹å¾µ)\n",
    "            m_sin = np.sin(2 * np.pi * curr_date.month / 12)\n",
    "            m_cos = np.cos(2 * np.pi * curr_date.month / 12)\n",
    "            # æ§‹é€  [tavg, tmax, tmin, prcp(0), snowf, snowdmax, sunhour(0.5), m_sin, m_cos]\n",
    "            new_entry = np.array([pred[0], pred[1], pred[2], 0, pred[3], pred[4], 0.5, m_sin, m_cos]).reshape(1, 1, 9)\n",
    "            current_batch = np.append(current_batch[:, 1:, :], new_entry, axis=1)\n",
    "\n",
    "    # 5. è©•åˆ†èˆ‡æ˜Ÿæ˜Ÿè½‰åŒ–é‚è¼¯ (å»¶ç”¨ä¹‹å‰çš„é‚è¼¯)\n",
    "# 5. è©•åˆ†èˆ‡æ˜Ÿæ˜Ÿè½‰åŒ–é‚è¼¯\n",
    "    final_scores = []\n",
    "    for day in predictions_list:\n",
    "        score = 0\n",
    "        score += day['snowdmax'] * 1.0  # ç©é›ªæ·±åº¦åˆ†\n",
    "        if day['snowf'] > 2 and day['tmax'] < 0: \n",
    "            score += 30 # ç²‰é›ªåˆ†\n",
    "        if day['tmax'] > 3: \n",
    "            score -= 20 # èé›ªæ‰£åˆ†\n",
    "\n",
    "        # é€™è£¡è¦ç¢ºä¿æ‰€æœ‰çš„ç¸®é€² (Indentation) éƒ½å°é½Š\n",
    "        star_count = 1\n",
    "        if score >= 80: star_count = 5\n",
    "        elif score >= 50: star_count = 4\n",
    "        elif score >= 20: star_count = 3\n",
    "        elif score > 0: star_count = 2\n",
    "\n",
    "        # --- é—œéµä¿®æ­£å€å¡Š ---\n",
    "        final_scores.append({\n",
    "            'date': day['date'],\n",
    "            'score': score,\n",
    "            'info': day,\n",
    "            'stars': \"â­\" * star_count + \"â˜†\" * (5 - star_count),\n",
    "            'tips': get_travel_tips(star_count, day) # æ³¨æ„é€™è¡Œè¦è·Ÿä¸Šé¢çš„å°é½Š\n",
    "        })\n",
    "    # ------------------\n",
    "\n",
    "    if not final_scores:\n",
    "        return None, []\n",
    "\n",
    "    best_day = max(final_scores, key=lambda x: x['score'])\n",
    "    return best_day, final_scores\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "if st.sidebar.button(\"é–‹å§‹AIé æ¸¬\"):\n",
    "    with st.spinner('AIæ­£åœ¨è¨ˆç®—é›ªæ³ä¸­...'):\n",
    "        # é€™è£¡å‘¼å«ä½ ä¹‹å‰å¯«å¥½çš„å‡½å¼\n",
    "        best_day, all_results = get_ski_recommendation(str(start_date), str(end_date), model, scaler, df)\n",
    "        \n",
    "        # é¡¯ç¤ºæœ€ä½³æ—¥æœŸ (æ˜Ÿæ˜Ÿèˆ‡å°æ’‡æ­¥)\n",
    "        st.success(f\"ğŸ† æœ€ä½³æ¨è–¦æ—¥ï¼š{best_day['date'].date()}\")\n",
    "        st.metric(\"æ¨è–¦æŒ‡æ•¸\", best_day['stars'])\n",
    "        st.info(f\"ğŸ’¡ æ•™ç·´å»ºè­°ï¼š{best_day['tips']}\")\n",
    "        \n",
    "        # é¡¯ç¤ºè©³ç´°æ•¸æ“šè¡¨\n",
    "        st.subheader(\"ğŸ“Š è©³ç´°é å ±æ•¸æ“š\")\n",
    "        res_df = pd.DataFrame([r['info'] for r in all_results])\n",
    "        st.dataframe(res_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
