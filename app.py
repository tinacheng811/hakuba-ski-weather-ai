import streamlit as st
import pandas as pd
import numpy as np
from tensorflow.keras.models import load_model
import pickle
from datetime import datetime

# --- 1. æ ¸å¿ƒå·¥å…·å‡½å¼ (å¿…é ˆæ”¾åœ¨ä¸»ç¨‹å¼å‰é¢) ---

def get_star_rating(score):
    if score >= 80: star_count = 5
    elif score >= 50: star_count = 4
    elif score >= 20: star_count = 3
    elif score > 0: star_count = 2
    else: star_count = 1
    stars = "â­" * star_count + "â˜†" * (5 - star_count)
    comments = ["æ¥µä¸æ¨è–¦", "å‹‰å¼·å¯ä»¥", "æ™®é€š", "è‰¯å¥½", "æ¥µä½³ï¼"]
    return stars, comments[star_count - 1], star_count

def get_travel_tips(star_count, info):
    tips = {
        5: "â„ï¸ã€æ¥µä½³ï¼šç²‰é›ªå¤©å ‚ã€‘ä»Šå¤©é›ªè³ªå®Œç¾ï¼å»ºè­°ä¸€æ—©å‡ºç™¼æ¶é ­é¦™ï¼Œäº«å—é¬†è»Ÿç²‰é›ªã€‚",
        4: "ğŸ¿ã€å„ªè‰¯ï¼šæ»‘é›ªé¦–é¸ã€‘é›ªé‡å……è¶³ï¼Œæ˜¯éå¸¸é©åˆç·´ç¿’æŠ€è¡“çš„ä¸€å¤©ã€‚",
        3: "ğŸŒ¤ï¸ã€æ™®é€šï¼šä¼‘é–’æ»‘é›ªã€‘å»ºè­°ä»¥ä¼‘é–’æ»‘è¡Œç‚ºä¸»ï¼Œæ³¨æ„é˜²æ›¬ã€‚",
        2: "âš ï¸ã€æ³¨æ„ï¼šé›ªè³ªåç¡¬ã€‘æ°£æº«æ³¢å‹•ï¼Œé›ªé¢å¯èƒ½çµå†°ï¼Œæ–°æ‰‹è«‹å‹™å¿…é…æˆ´è­·å…·ã€‚",
        1: "ğŸ ã€å»ºè­°ï¼šå®¤å…§æ´»å‹•ã€‘ä»Šæ—¥é›ªæ³ä¸ä½³ã€‚å»ºè­°å»æ³¡æº«æ³‰æˆ–åœ¨å’–å•¡å»³æ”¾é¬†ã€‚"
    }
    temp_tip = ""
    if info['tmin'] < -10: temp_tip = " ğŸ¥¶ æé†’ï¼šæ°£æº«æ¥µä½ï¼Œæ³¨æ„é˜²å‡å‚·ï¼"
    elif info['tmax'] > 3: temp_tip = " ğŸ’§ æé†’ï¼šæ°£æº«å›å‡ï¼Œé›ªè³ªè¼ƒé»ã€‚"
    return tips.get(star_count, "è³‡è¨Šä¸è¶³") + temp_tip

def get_ski_recommendation(start_date_str, end_date_str, model, scaler, df, window_size=7):
    start_date = pd.to_datetime(start_date_str)
    end_date = pd.to_datetime(end_date_str)
    last_date = df['Date'].max()
    features_cols = ['tavg', 'tmax', 'tmin', 'prcp', 'snowf', 'snowdmax', 'sunhour', 'month_sin', 'month_cos']
    
    predictions_list = []
    
    # ç°¡åŒ–é‚è¼¯ï¼šçµ±ä¸€ä½¿ç”¨é æ¸¬ (é©åˆéƒ¨ç½²æ¼”ç¤º)
    days_to_predict = (end_date - last_date).days
    last_data_raw = df[features_cols].tail(window_size).fillna(0).values
    current_batch = scaler.transform(last_data_raw).reshape(1, window_size, 9)

    for i in range(days_to_predict):
        pred = model.predict(current_batch, verbose=0)[0]
        curr_date = last_date + pd.Timedelta(days=i+1)
        if start_date <= curr_date <= end_date:
            dummy = np.zeros((1, 9))
            dummy[0, 0:3] = pred[0:3]
            dummy[0, 4:6] = pred[3:5]
            res = scaler.inverse_transform(dummy)[0]
            predictions_list.append({
                'date': curr_date, 'tavg': res[0], 'tmax': res[1], 'tmin': res[2],
                'snowf': res[4], 'snowdmax': res[5]
            })
        m_sin, m_cos = np.sin(2 * np.pi * curr_date.month / 12), np.cos(2 * np.pi * curr_date.month / 12)
        new_entry = np.array([pred[0], pred[1], pred[2], 0, pred[3], pred[4], 0.5, m_sin, m_cos]).reshape(1, 1, 9)
        current_batch = np.append(current_batch[:, 1:, :], new_entry, axis=1)

    final_scores = []
    for day in predictions_list:
        score = day['snowdmax'] * 1.0
        if day['snowf'] > 2 and day['tmax'] < 0: score += 30
        if day['tmax'] > 3: score -= 20
        stars_str, status, star_count = get_star_rating(score)
        final_scores.append({
            'date': day['date'], 'score': score, 'info': day,
            'stars': stars_str, 'tips': get_travel_tips(star_count, day)
        })
    best_day = max(final_scores, key=lambda x: x['score']) if final_scores else None
    return best_day, final_scores

# --- 2. Streamlit ä»‹é¢ ---

st.set_page_config(page_title="ç™½é¦¬æ‘æ»‘é›ªé æ¸¬", page_icon="â„ï¸")
st.title("â„ï¸ ç™½é¦¬æ‘æ»‘é›ª AI ç‰¹åŠ©")

@st.cache_resource
def load_assets():
    model = load_model('my_lstm_model.h5')
    with open('scaler.pkl', 'rb') as f:
        scaler = pickle.load(f)
    df = pd.read_csv('weather_exam.csv')
    df['Date'] = pd.to_datetime(df['Date'])
    return model, scaler, df

try:
    model, scaler, df = load_assets()
    
    st.sidebar.header("è¡Œç¨‹è¨­å®š")
    start_input = st.sidebar.date_input("é–‹å§‹æ—¥æœŸ", datetime(2026, 2, 10))
    end_input = st.sidebar.date_input("çµæŸæ—¥æœŸ", datetime(2026, 2, 15))

    if st.sidebar.button("åŸ·è¡Œ AI åˆ†æ"):
        best, results = get_ski_recommendation(str(start_input), str(end_input), model, scaler, df)
        
        if best:
            st.success(f"ğŸ† æœ€ä½³æ¨è–¦æ—¥ï¼š{best['date'].date()}")
            col1, col2 = st.columns(2)
            col1.metric("æ»‘é›ªæŒ‡æ•¸", best['stars'])
            col2.metric("é è¨ˆç©é›ª", f"{best['info']['snowdmax']:.1f} cm")
            st.info(f"ğŸ’¡ æ•™ç·´å»ºè­°ï¼š{best['tips']}")
            
            st.divider()
            st.subheader("ğŸ“… å€é–“è©³ç´°é å ±")
            display_df = pd.DataFrame([{
                'æ—¥æœŸ': r['date'].date(),
                'æœ€é«˜æº«': f"{r['info']['tmax']:.1f}Â°C",
                'æœ€ä½æº«': f"{r['info']['tmin']:.1f}Â°C",
                'ç©é›ª(cm)': round(r['info']['snowdmax'], 1),
                'æŒ‡æ•¸': r['stars']
            } for r in results])
            st.table(display_df)
        else:
            st.warning("è«‹é¸æ“‡è³‡æ–™é›†æ—¥æœŸä¹‹å¾Œçš„æœªä¾†å€é–“ï¼ˆä¾‹å¦‚ 2026 å¹´ä¹‹å¾Œï¼‰ã€‚")

except Exception as e:
    st.error(f"è¼‰å…¥å¤±æ•—ï¼šè«‹ç¢ºä¿ GitHub ä¸­æœ‰ model.h5, scaler.pkl å’Œ weather_exam.csv ä¸‰å€‹æª”æ¡ˆã€‚")
    st.write(f"éŒ¯èª¤ç´°ç¯€: {e}")