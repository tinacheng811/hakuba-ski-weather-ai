import streamlit as st
import pandas as pd
import numpy as np
import pickle
from datetime import datetime
from tensorflow.keras.models import load_model

# =================================================================
# 1. ç³»çµ±å¸¸æ•¸å®šç¾© (Constants) - æ–¹ä¾¿æ—¥å¾Œç¶­è­·ï¼Œä¸é ˆæ·±å…¥ç¨‹å¼ç¢¼ä¿®æ”¹
# =================================================================
MODEL_FILE  = 'my_lstm_model.h5'
SCALER_FILE = 'scaler.pkl'
DATA_FILE   = 'weather_exam.csv'
WINDOW_SIZE = 7  # æ¨¡å‹è¨“ç·´æ™‚ä½¿ç”¨çš„æ™‚åºé•·åº¦
# åš´æ ¼å°é½Šè¨“ç·´æ™‚çš„ 9 å€‹ç‰¹å¾µæ¬„ä½é †åº
FEATURES    = ['tavg', 'tmax', 'tmin', 'prcp', 'snowf', 'snowdmax', 'sunhour', 'month_sin', 'month_cos']

# =================================================================
# 2. é‚è¼¯å°è£ (Logic Layer) - æ•¸å€¼è¨ˆç®—èˆ‡é¡¯ç¤ºé‚è¼¯åˆ†é›¢
# =================================================================

def get_star_advice(score, info):
    """æ ¹æ“šè©•åˆ†è½‰æ›ç‚ºæ˜Ÿæ˜Ÿèˆ‡æ—…éŠå»ºè­°"""
    if score >= 80: stars, level = "â­â­â­â­â­", 5
    elif score >= 50: stars, level = "â­â­â­â­", 4
    elif score >= 20: stars, level = "â­â­â­", 3
    elif score > 0: stars, level = "â­â­", 2
    else: stars, level = "â­", 1

    tips = {
        5: "â„ï¸ã€ç²‰é›ªå¤©å ‚ã€‘é›ªè³ªæ¥µä½³ï¼Œå¼·çƒˆå»ºè­°ä¸€æ—©å‡ºç™¼äº«å—é¬†è»Ÿç²‰é›ªã€‚",
        4: "ğŸ¿ã€æ»‘é›ªé¦–é¸ã€‘é›ªé‡å……è¶³ï¼Œéå¸¸é©åˆç²¾é€²æ»‘é›ªæŠ€è¡“ã€‚",
        3: "ğŸŒ¤ï¸ã€ä¼‘é–’èˆ’é©ã€‘é©åˆè¼•é¬†æ»‘è¡Œï¼Œè«‹æ³¨æ„é™½å…‰åå°„èˆ‡é˜²æ›¬ã€‚",
        2: "âš ï¸ã€æ³¨æ„å†°é¢ã€‘æ°£æº«æ³¢å‹•å¯èƒ½å°è‡´é›ªé¢çµå†°ï¼Œè«‹æ³¨æ„å®‰å…¨ã€‚",
        1: "ğŸ ã€å»ºè­°ä¼‘æ¯ã€‘é›ªæ³ä¸ä½³ï¼Œæ¨è–¦å‰å¾€ç™½é¦¬æ‘æ³¡æº«æ³‰æ”¾é¬†ã€‚"
    }
    # æ ¹æ“šæ°£æº«å‹•æ…‹å¢åŠ å°æé†’
    extra = " ğŸ¥¶ æ¥µå¯’æ³¨æ„" if info['tmin'] < -10 else " ğŸ’§ èé›ªæ³¨æ„" if info['tmax'] > 3 else ""
    return stars, tips.get(level) + extra

def run_ai_prediction(start_date, end_date, model, scaler, df):
    """åŸ·è¡Œ LSTM éè¿´é æ¸¬æ¼”ç®—æ³•"""
    # æ±ºå®šã€Œç¨®å­è³‡æ–™ã€åˆ‡ç‰‡çµ‚é»ï¼šè‹¥æ˜¯æœªä¾†å‰‡å¾ DB æœ€å¾Œä¸€å¤©é–‹å§‹ï¼›æ­·å²é©—è­‰å‰‡å¾é¸å®šæ—¥å‰ä¸€å¤©é–‹å§‹
    last_db_date = df['Date'].max()
    seed_end = last_db_date if start_date > last_db_date else start_date - pd.Timedelta(days=1)
    
    # æå–æœ€å¾Œ window_size å¤©çš„è³‡æ–™ä½œç‚ºæ¨¡å‹è¼¸å…¥èµ·é»
    seed_df = df[df['Date'] <= seed_end].tail(WINDOW_SIZE)
    if len(seed_df) < WINDOW_SIZE: return []
    
    # æ­£è¦åŒ–ç‰¹å¾µä¸¦èª¿æ•´ç¶­åº¦ç‚º (1, 7, 9)
    current_batch = scaler.transform(seed_df[FEATURES].fillna(0).values).reshape(1, WINDOW_SIZE, 9)
    predictions = []
    days_to_run = (end_date - seed_end).days

    for i in range(days_to_run):
        # 1. åŸ·è¡Œæ¨¡å‹é æ¸¬ (è¼¸å‡º 5 å€‹å€¼: tavg, tmax, tmin, snowf, snowdmax)
        raw_pred = model.predict(current_batch, verbose=0)[0]
        curr_date = seed_end + pd.Timedelta(days=i+1)
        
        # 2. æ•¸å€¼é‚„åŸï¼šå»ºç«‹ 9 æ¬„ dummy çŸ©é™£ä»¥åŒ¹é… Scaler
        dummy = np.zeros((1, 9))
        dummy[0, 0:3], dummy[0, 4:6] = raw_pred[0:3], raw_pred[3:5]
        res = scaler.inverse_transform(dummy)[0]
        
        day_info = {
            'date': curr_date, 'tavg': res[0], 'tmax': res[1], 
            'tmin': res[2], 'snowf': res[4], 'snowdmax': res[5]
        }
        
        # 3. åƒ…è¨˜éŒ„ä½¿ç”¨è€…è¦æ±‚çš„å€é–“
        if start_date <= curr_date <= end_date:
            # è¨ˆç®—æ»‘é›ªè©•åˆ†é‚è¼¯
            score = day_info['snowdmax'] * 1.0
            if day_info['snowf'] > 2 and day_info['tmax'] < 0: score += 30
            if day_info['tmax'] > 3: score -= 20
            
            stars, tips = get_star_advice(score, day_info)
            predictions.append({'info': day_info, 'stars': stars, 'tips': tips, 'score': score})
            
        # 4. ç‰¹å¾µå·¥ç¨‹ï¼šè¨ˆç®—ä¸‹ä¸€å¤©çš„ Sin/Cos ä¸¦æ›´æ–° Batch é€²è¡Œéè¿´
        m_sin = np.sin(2 * np.pi * curr_date.month / 12)
        m_cos = np.cos(2 * np.pi * curr_date.month / 12)
        new_row = np.array([raw_pred[0], raw_pred[1], raw_pred[2], 0, raw_pred[3], raw_pred[4], 0.5, m_sin, m_cos])
        current_batch = np.append(current_batch[:, 1:, :], new_row.reshape(1, 1, 9), axis=1)

    return predictions

# =================================================================
# 3. è³‡æ–™åŠ è¼‰èˆ‡åˆå§‹åŒ– (Initialization)
# =================================================================

@st.cache_resource
def setup_environment():
    """è¼‰å…¥ AI æ¨¡å‹è³‡ç”¢ä¸¦é€²è¡Œè³‡æ–™é è™•ç†"""
    try:
        model = load_model(MODEL_FILE, compile=False)
        with open(SCALER_FILE, 'rb') as f:
            scaler = pickle.load(f)
        df = pd.read_csv(DATA_FILE)
        df['Date'] = pd.to_datetime(df['Date'])
        # é å…ˆè¨ˆç®—é€±æœŸæ€§ç‰¹å¾µï¼Œæå‡é‹è¡Œæ•ˆç‡
        df['month_sin'] = np.sin(2 * np.pi * df['Date'].dt.month / 12)
        df['month_cos'] = np.cos(2 * np.pi * df['Date'].dt.month / 12)
        return model, scaler, df
    except Exception as e:
        st.error(f"ğŸš¨ ç³»çµ±åˆå§‹åŒ–å¤±æ•—: {e}")
        return None, None, None

# =================================================================
# 4. Web ä»‹é¢ä½ˆå±€ (UI Layout)
# =================================================================

st.set_page_config(page_title="ç™½é¦¬æ‘æ»‘é›ªå¤©æ°£AIåŠ©ç†", layout="centered")
st.title("â„ï¸ ç™½é¦¬æ‘æ»‘é›ªå¤©æ°£AIåŠ©ç†")

model, scaler, df = setup_environment()

if model is not None:
    # å´é‚Šæ¬„ï¼šåŠŸèƒ½é¸å–®
    st.sidebar.header("ğŸ•¹ï¸ åŠŸèƒ½é¸å–®")
    app_mode = st.sidebar.radio("é¸æ“‡åŠŸèƒ½æ¨¡å¼", ["æœªä¾†è¡Œç¨‹é æ¸¬", "æ­·å²æ¨¡å‹é©—è­‰"])

    if app_mode == "æœªä¾†è¡Œç¨‹é æ¸¬":
        st.sidebar.subheader("ğŸ“… æ—…éŠæ—¥æœŸè¨­å®š")
        d_start = st.sidebar.date_input("é–‹å§‹æ—¥æœŸ", datetime(2026, 2, 10))
        d_end = st.sidebar.date_input("çµæŸæ—¥æœŸ", datetime(2026, 2, 15))
        
        if st.sidebar.button("é–‹å§‹é æ¸¬", type="primary"):
            results = run_ai_prediction(pd.to_datetime(d_start), pd.to_datetime(d_end), model, scaler, df)
            if results:
                best = max(results, key=lambda x: x['score'])
                st.success(f"ğŸ¯ æœ€ä½³æ¨è–¦æ—¥ï¼š{best['info']['date'].date()}")
                c1, c2 = st.columns(2)
                c1.metric("æŒ‡æ•¸", best['stars'])
                c2.metric("é ä¼°ç©é›ª", f"{best['info']['snowdmax']:.1f} cm")
                st.info(f"ğŸ’¡ å»ºè­°ï¼š{best['tips']}")
                
                # è©³ç´°è¡¨æ ¼
                st.divider()
                st.subheader("ğŸ“… å€é–“è©³ç´°é å ±")
                st.table(pd.DataFrame([{
                    'æ—¥æœŸ': r['info']['date'].date(),
                    'æœ€é«˜æº«': f"{r['info']['tmax']:.1f}Â°C",
                    'æœ€ä½æº«': f"{r['info']['tmin']:.1f}Â°C",
                    'ç©é›ª(cm)': round(r['info']['snowdmax']:.1f, 1),
                    'æŒ‡æ•¸': r['stars']
                } for r in results]))
            else:
                st.warning("è«‹é¸æ“‡æœªä¾†æ—¥æœŸã€‚")

else:
        # --- æ­·å²æ¨¡å‹é©—è­‰æ¨¡å¼ ---
        st.sidebar.subheader("ğŸ” æ­·å²è³‡æ–™æ ¸å°")
        
        # 1. åœ¨å´é‚Šæ¬„æ”¾ç½®æ—¥æœŸé¸æ“‡å™¨
        target_v = st.sidebar.date_input(
            "é¸æ“‡é©—è­‰æ—¥æœŸ", 
            df['Date'].max().date(),
            help="è«‹é¸æ“‡ CSV è³‡æ–™åº«ä¸­å·²å­˜åœ¨çš„æ—¥æœŸé€²è¡Œæ ¸å°"
        )
        
        # 2. å°‡åŸ·è¡ŒæŒ‰éˆ•ç§»å…¥å´é‚Šæ¬„ (ä¸¦æ”¹ç‚º Primary é¡è‰²å¼·èª¿)
        btn_verify = st.sidebar.button("å•Ÿå‹• AI é©—è­‰", type="primary")

        # 3. ä¸»ç•«é¢é‚è¼¯ï¼šåªæœ‰åœ¨æŒ‰ä¸‹æŒ‰éˆ•å¾Œæ‰åŸ·è¡Œèˆ‡é¡¯ç¤º
        if btn_verify:
            results = run_ai_prediction(pd.to_datetime(target_v), pd.to_datetime(target_v), model, scaler, df)
            actual = df[df['Date'] == pd.to_datetime(target_v)]
            
            if results and not actual.empty:
                p, a = results[0]['info'], actual.iloc[0]
                st.subheader(f"ğŸ“Š é æ¸¬èˆ‡è§€æ¸¬å°æ¯” ({target_v})")
                
                # ä½¿ç”¨å¤§å­—é«”é¡¯ç¤ºæ ¸å¿ƒæŒ‡æ¨™å°ç…§
                col1, col2, col3 = st.columns(3)
                col1.metric("è§€æ¸¬é …ç›®", "å¹³å‡æ°£æº«", "ç©é›ªæ·±åº¦")
                col2.metric("çœŸå¯¦è§€æ¸¬", f"{a['tavg']:.1f}Â°C", f"{a['snowdmax']:.1f}cm")
                col3.metric("AIé æ¸¬å€¼", f"{p['tavg']:.1f}Â°C", f"{p['snowdmax']:.1f}cm")
                
                # èª¤å·®åˆ†æ
                error = abs(a['tavg'] - p['tavg'])
                if error < 2.0:
                    st.success(f"âœ… æ¨¡å‹è¡¨ç¾ä¸å·®ï¼šæº«åº¦èª¤å·®åƒ… {error:.2f}Â°C")
                else:
                    st.warning(f"ğŸ§ èª¤å·®è¼ƒå¤§ ({error:.2f}Â°C)ï¼Œå»ºè­°æª¢æŸ¥ç•¶å¤©æ˜¯å¦æœ‰æ¥µç«¯å¤©æ°£ç´€éŒ„ã€‚")
            else:
                st.error("æ­¤æ—¥æœŸä¸åœ¨è³‡æ–™åº«ä¸­ï¼Œæˆ–å‰ç½®è³‡æ–™ä¸è¶³ (éœ€è‡³å°‘æœ‰ 7 å¤©æ­·å²ç´€éŒ„)ã€‚")
